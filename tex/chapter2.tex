% !TeX root=../main.tex
\chapter{پیشینه پژوهش}
%\thispagestyle{empty} 
\section{تولید آزمایه به صورت خودکار}
تولید خودکار آزمایه 
\LTRfootnote{Testcase}
به معنای ایجاد سناریوهای آزمون به صورت خودکار، بدون نیاز به دخالت دستی است. در این روش آزمونگر از تکنیک‌ها و ابزارهای ویژه‌ای استفاده می‌کند تا سناریوهای متنوعی برای آزمون نرم‌افزار تحت آزمون
\LTRfootnote{System Under Test}
 ایجاد کند. مزایای این روش عبارت‌اند از:
\begin{itemize}
	\item \textbf{پوشش گسترده‌تر آزمون:} تولید خودکار آزمایه‌ها، مواردی را پوشش می‌دهد که ممکن است در آزمون‌های دستی نادیده گرفته شوند. این امر به ویژه در آزمون نرم‌افزارهای پیچیده و بزرگ اهمیت بیشتری دارد.
	\item \textbf{افزایش کارایی آزمون:} با خودکارسازی فرآیند تولید آزمایه‌ها، می‌توان تعداد زیادی آزمایه در مدت زمان کوتاهی ایجاد کرد، که این کارایی در فازهای توسعه و نگهداری نرم‌افزار بسیار مفید است.
	\item \textbf{کشف باگ‌های ناشناخته:} تولید خودکار آزمایه‌ها به شناسایی باگ‌هایی کمک می‌کند که ممکن است در سناریوهای پیش‌بینی‌نشده رخ دهند. آزمون‌های تصادفی به خصوص در این زمینه بسیار مؤثر هستند.
	\item \textbf{کاهش دخالت انسانی:} خودکارسازی تولید آزمایه‌ها باعث کاهش خطاهای انسانی می‌شود و دقت و اطمینان آزمون‌ها را افزایش می‌دهد.
\end{itemize}

\section{آزمون تصادفی}
آزمون تصادفی \LTRfootnote{Random Testing} یک روش آزمون نرم‌افزار جعبه سیاه\LTRfootnote{Black Box Testing} است که در آن سیستم تحت آزمون با ورودی‌های تولید شده به صورت تصادفی ارزیابی می‌شود. هدف اصلی آزمون تصادفی، شناسایی اشکالات نرم‌افزار و اطمینان از قابلیت اطمینان و استحکام نرم‌افزار در مواجهه با انواع مختلف سناریوهای ورودی است.
\subsection{فرآیند تولید آزمایه توسط آزمون تصادفی}
فرآیند تولید آزمایه به صورت خودکار توسط روش آزمون تصادفی را می‌توان به صورت زیر ترسیم کرد:

\begin{enumerate}
	\item \textbf{تعریف فضای ورودی\LTRfootnote{Input Domain}:} در این مرحله محدوده و نوع ورودی‌هایی که نرم‌افزار می‌تواند بپذیرد، مشخص می‌گردد. این شامل تعیین دامنه‌های ورودی و محدودیت‌ها برای اطمینان از صحت موارد آزمون تولید شده است.
	\item \textbf{تولید موارد آزمون:} مجموعه‌ای از مقادیر ورودی به صورت تصادفی در داخل فضای ورودی تعریف شده تولید می‌شود. این ورودی‌ها باید طیف گسترده‌ای از سناریوهای ممکن را پوشش دهند تا احتمال کشف اشکالات افزایش یابد.
	\item \textbf{اجرای آزمون:} نرم‌افزار با استفاده از ورودی‌های تولید شده تصادفی اجرا شده و رفتار و خروجی‌های آن برای هر گونه ناهنجاری یا نتایج غیرمنتظره نظارت می‌شود.
	\item \textbf{ارزیابی خروجی‌ها:} خروجی‌های واقعی نرم‌افزار با خروجی‌های مورد انتظار (در صورت موجود بودن) مقایسه می‌شوند تا هر گونه تفاوت شناسایی گردد. در مواردی که خروجی مورد انتظار از پیش تعیین نشده است، از روش‌های اکتشافی یا اوراکل‌ها
		\LTRfootnote{Oracle}
	 برای ارزیابی درستی رفتار سیستم تحت آزمون استفاده می‌شود.
	\item \textbf{شناسایی و تحلیل اشکالات:} هر گونه انحراف یا خرابی که در حین آزمون شناسایی شود، تحلیل می‌گردد تا علل زیربنایی آن تشخیص داده شود.
\end{enumerate}


\subsection{مزایای آزمون تصادفی}
آزمون تصادفی چندین مزیت دارد که آن را به یک تکنیک ارزشمند در آزمون نرم‌افزار تبدیل می‌کند:
\begin{itemize}
	\item \textbf{سادگی:} این روش به سادگی قابل پیاده‌سازی است و نیازی به دانش عمیق از ساختار داخلی نرم‌افزار ندارد. موارد آزمون می‌توانند به صورت خودکار و بدون تلاش دستی، به صورت نامحدود تولید شوند.
	\item \textbf{خودکارسازی:} آزمون تصادفی می‌تواند به طور کامل خودکار شود و امکان آزمون پیوسته و بدون نیاز به نظارت انسانی را فراهم کند. این امر نیاز به دخالت انسانی را کاهش می‌دهد.
	\item \textbf{پوشش گسترده:} با تولید مجموعه‌ای متنوع از ورودی‌های تصادفی، آزمون تصادفی می‌تواند طیف گسترده‌ای از سناریوهای ورودی را پوشش دهد. این امر احتمال کشف اشکالات نادر یا غیرمنتظره‌ای که ممکن است از طریق دیگر روش‌های آزمون نرم‌افزار شناسایی نشوند را افزایش می‌دهد.
\end{itemize}

\subsection{معایب آزمون تصادفی}
با وجود مزایای آن، آزمون تصادفی چندین محدودیت دارد که می‌تواند بر اثربخشی آن تأثیر بگذارد:
\begin{itemize}
	\item \textbf{ناکارآمدی:} این روش می‌تواند از نظر زمان و منابع محاسباتی ناکارآمد باشد. بسیاری از ورودی‌های تولید شده ممکن است موارد آزمون معناداری را تحریک نکنند، که منجر به هدر رفتن تلاش‌ها و منابع استفاده شده جهت آزمون می‌شود.
	\item \textbf{تکرارپذیری:} آزمون تصادفی ممکن است موارد آزمون تکراری تولید کند که ارزش افزوده زیادی ندارند. نبود تمرکز بر نواحی بحرانی می‌تواند منجر به حجم بالای آزمون‌ها با نرخ شناسایی اشکال پایین شود.
	\item \textbf{تمرکز محدود:} آزمون تصادفی نواحی ورودی خاص یا نقاط خرابی بحرانی را اولویت‌بندی نمی‌کند. بنابراین، ممکن است اشکالات مهمی که در نواحی کمتر آزمون شده متمرکز شده‌اند را نادیده بگیرد.
\end{itemize}

%===============================================================================================================

\section{آزمون تصادفی تطبیقی}
آزمون تصادفی تطبیقی \LTRfootnote{Adaptive Random Testing}  با هدف بهبود آزمون تصادفی سنتی به وجود آمد و به ناکارآمدی‌ها و محدودیت‌های آن پرداخت. مفهوم آزمون تصادفی تطبیقی برای افزایش قابلیت‌های شناسایی اشکال آزمون تصادفی، با استفاده از استراتژی‌های تطبیقی که انتخاب موارد آزمون را هدایت می‌کنند، معرفی شد. آزمون تصادفی تطبیقی هدف دارد تا نرخ شناسایی اشکال بهتر را با حفظ مزایای سادگی و خودکارسازی آزمون تصادفی، بیشتر کند.

\subsection{فرضیه اصلی آزمون تصادفی تطبیقی}

توسعه آزمون تصادفی تطبیقی به دلیل نیاز به کاهش تکرارپذیری و ناکارآمدی مرتبط با تولید موارد آزمون به صورت تصادفی خالص به وجود آمد. محققان مشاهده کردند که اشکالات نرم‌افزار تمایل دارند در برخی نواحی فضای ورودی متمرکز شوند و به عبارت دیگر \textbf{نقاط خطا و شکست درون دامنه ورودی به صورت ناحیه‌ای هستند و تمایل به پیوسته بودن دارند.} در نتیجه هر چه تراکم آزمایه‌ها روی دامنه ورودی بیشتر باشد، احتمال کشف خطای جدید بیشتر خواهد بود. آزمون تصادفی تطبیقی از این مشاهده بهره می‌برد و از بازخورد موارد آزمون قبلی برای هدایت تولید موارد آزمون بعدی استفاده می‌کند. به طور کلی، آزمون تصادفی تطبیقی، آزمون تصادفی سنتی را با استفاده از تکنیک‌هایی که توزیع یکنواخت‌تری از موارد آزمون را در سراسر فضای ورودی تضمین می‌کنند، تقویت می‌کند. اصل کلیدی روش آزمون تصادفی تطبیقی این است که حداکثر تنوع موارد آزمون را به دست آورد و به این ترتیب، احتمال شناسایی خطا را افزایش دهد.

\subsection{فرآیند تولید آزمایه توسط آزمون تصادفی تطبیقی}

فرآیند تولید آزمایه به صورت خودکار توسط روش آزمون تصادفی تطبیقی را می‌توان به صورت زیر ترسیم کرد:
\begin{itemize}
	\item \textbf{تولید مجموعه کاندید\LTRfootnote{Candidate Set}:} در این مرحله ابتدایی، یک مجموعه‌ای از آزمایه‌ها با استفاده از روش آزمون تصادفی تولید می‌شود. این آزمایه‌ها به صورت تصادفی روی فضای ورودی تعریف شده از نرم‌افزار ایجاد می‌شوند.
	\item \textbf{انتخاب آزمایه:} از مجموعه کاندید تولید شده، یک آزمایه بر اساس یک استراتژی خاص که منحصراً به روش آزمون تصادفی تطبیقی مربوط است، انتخاب می‌شود. این استراتژی معمولاً به منظور به حداکثر رساندن فاصله آزمایه‌ها در فضای ورودی عمل می‌کند. با انتخاب آزمایه‌هایی که به طور گسترده‌تری پراکنده شده‌اند، آزمون تصادفی تطبیقی سعی دارد که احتمال کشف خطاها را نسبت به آزمون تصادفی سنتی افزایش دهد.
	\item \textbf{تکرار:} آزمایه انتخاب شده به مجموعه آزمایه‌های انتخاب شده \LTRfootnote{Executed Set}اضافه می‌شود و مراحل فوق به صورت تکراری انجام می‌شود. فرآیند تولید یک مجموعه کاندید جدید و انتخاب یک آزمایه ادامه می‌یابد تا زمانی که شرط خاتمه ارضاء شود که برای مثال شرط خاتمه می‌تواند رسیدن به تعداد مشخصی آزمایه باشد.
\end{itemize}
با دنبال کردن این مراحل، آزمون تصادفی تطبیقی تلاش می‌کند تا با تمرکز بر توزیع یکنواخت‌تر آزمایه‌ها، قابلیت کشف خطا را در مقایسه با آزمون تصادفی سنتی بهبود بخشد.

\subsection{مزایای آزمون تصادفی تطبیقی}
آزمون تصادفی تطبیقی چندین مزیت دارد که آن را به جایگزینی برتر برای آزمون تصادفی سنتی تبدیل می‌کند. در ادامه به برخی از این مزیت‌ها اشاره شده است:
\begin{itemize}
	\item \textbf{کاهش تکرارپذیری:} آزمون تصادفی تطبیقی با تولید موارد آزمون متنوع تکرارپذیری را کاهش می‌دهد. این امر ارزش هر مورد آزمون را به حداکثر می‌رساند و تلاش‌های بیهوده آزمون را به حداقل می‌رساند.
	\item \textbf{افزایش کارایی و نرخ شناسایی اشکال بالاتر:}‌ به دنبال کاهش تکرارپذیری موارد آزمون، کارایی روش آزمون تصادفی تطبیقی افزایش می‌یابد و فرآیند آزمون را بهبود می‌بخشد، که این خود منجر به نرخ شناسایی اشکال بالاتر با تعداد آزمایه کمتر می‌شود.
	\item \textbf{پوشش متعادل:} روش آزمون تصادفی تطبیقی، پوشش متعادل‌تری از فضای ورودی را به دست می‌آورد و خطر نادیده گرفتن نواحی مهم را کاهش می‌دهد. این پوشش جامع، استحکام کلی نرم‌افزار را افزایش می‌دهد.
	\item \textbf{بهینه‌سازی منابع:} با بهبود کارایی تولید موارد آزمون، آزمون تصادفی تطبیقی از منابع محاسباتی و زمانی بهینه استفاده می‌کند. این امر آزمون تصادفی تطبیقی را به یک راه‌حل عملی و مقیاس‌پذیر برای آزمون نرم‌افزار در مقیاس بزرگ تبدیل می‌کند.
\end{itemize}

\subsection{سربار محاسباتی پیاده سازی آزمون تصادفی تطبیقی}
در مرحله انتخاب آزمایه از فرآیند پیاده‌سازی روش آزمون تصادفی تطبیقی، لازم است که فاصله بین هر آزمایه درون مجموعه کاندید و هر آزمایه درون مجموعه آزمایه‌های انتخاب‌شده در مراحل قبلی محاسبه شود. آزمایه‌ای که بیشترین فاصله را با مجموعه آزمایه‌های انتخاب‌شده دارد، انتخاب می‌شود. در این مرحله، تعداد محاسبات فاصله باید به اندازه‌ی (تعداد آزمایه‌های درون مجموعه کاندید × تعداد آزمایه‌های درون مجموعه آزمایه‌های انتخاب‌شده) انجام شود. با افزایش تعداد اعضای مجموعه آزمایه‌های انتخاب‌شده در هر بار تکرار فرآیند، سربار محاسباتی الگوریتم آزمون تصادفی تطبیقی افزایش می‌یابد. همچنین، تعداد اعضای درون مجموعه کاندید نیز تأثیر مستقیمی بر افزایش سربار محاسباتی الگوریتم دارد. در ادامه، استراتژی‌هایی که تاکنون برای کاهش اندازه مجموعه کاندید، کاهش تعداد آزمایه‌های درون مجموعه آزمایه‌های انتخاب‌شده در مراحل قبلی الگوریتم، و در نهایت کاهش تعداد محاسبات فاصله ارائه شده‌اند، شرح داده می‌شود.

\subsubsection{اندازه مجموعه کاندید ثابت}
اولین و پرکاربردترین استراتژی پیاده‌سازی الگوریتم آزمون تصادفی تطبیقی، استراتژی "انتخاب آزمایه از مجموعه کاندید با اندازه ثابت\LTRfootnote{Fixed Sized Candidate Set (FSCS)}" است. در این استراتژی، که توسط [نام پژوهشگر/منبع] ارائه شده است، اندازه مجموعه کاندید در کل روند اجرای الگوریتم ثابت در نظر گرفته می‌شود. بهترین مقدار برای اندازه مجموعه کاندید طبق پژوهش [نام پژوهشگر/منبع] برابر با ۱۰ اعلام شده است. البته، هر چه اندازه مجموعه کاندید را افزایش دهیم، این امر می‌تواند بر اثربخشی آزمایه‌های نهایی تأثیر داشته باشد. اما بر اساس این پژوهش، هنگامی که اندازه مجموعه کاندید از ۱۰ بیشتر باشد، میزان افزایش اثربخشی مجموعه آزمایه‌ها خیلی قابل توجه نیست.

\subsubsection{بزرگ شدن فضای آزمون در آزمون تصادفی تطبیقی}
یکی از چالش‌های اصلی و مهم در آزمون تصادفی تطبیقی، بزرگ شدن فضای آزمون است. با افزایش تعداد آزمایه‌های انتخاب شده، محاسبه فاصله هر آزمایه جدید با آزمایه‌های قبلی زمان‌بر و ناکارآمد می‌شود. این مسئله باعث افزایش پیچیدگی محاسباتی و کاهش کارایی فرآیند آزمون می‌شود. برای مقابله با این مشکل، استراتژی‌های مختلفی ارائه شده‌اند که هدف آن‌ها کاهش فضای آزمون و بهبود کارایی تولید آزمایه‌ها است.
\begin{itemize}
	\item \textbf{استراتژی فراموشی\LTRfootnote{Forgetting Strategy}:} استراتژی فراموشی به منظور مدیریت فضای آزمون و جلوگیری از بزرگ شدن بیش از حد آن استفاده می‌شود. در این روش، زمانی که مجموعه آزمایه‌های از قبل انتخاب‌شده به توزیع یکنواخت مناسبی می‌رسند، این مجموعه پاک می‌شود. با این کار، فقط آزمایه‌های جدیدتر و مرتبط‌تر در فرآیند محاسبه فاصله‌ها لحاظ می‌شوند. در این استراتژی با پاک کردن آزمایه‌های قدیمی‌تر، حجم داده‌های مورد نیاز برای محاسبه فاصله‌ها کاهش می‌یابد و محاسبات سریع‌تر و کارآمدتر انجام می‌شود. البته، احتمال از دست رفتن اطلاعات مفید از آزمایه‌های قبلی وجود دارد و همچنین معیارهای فراموشی باید به دقت تنظیم شوند تا بهترین نتیجه حاصل شود.
	
	\item \textbf{خوشه‌بندی \lr{K}-مرکز\LTRfootnote{K-means Clustering Strategy}:} خوشه‌بندی \lr{K}-مرکز یکی دیگر از استراتژی‌های کاهش فضای آزمون است. در این روش، آزمایه‌های انتخاب‌شده به خوشه‌هایی تقسیم می‌شوند و هر خوشه با یک نماینده (میانگین) که مرکز خوشه است، مشخص می‌شود. برای انتخاب آزمایه جدید، فاصله بین آزمایه‌های کاندید و نمایندگان خوشه‌ها محاسبه می‌شود. این استراتژی علاوه بر کاهش تعداد محاسبات فاصله، باعث مدیریت بهتر فضای آزمون می‌شود و فضای آزمون به صورت خوشه‌بندی‌شده نگهداری می‌شود. با این حال، این روش ممکن است پیچیدگی اجرای الگوریتم را افزایش دهد و تعیین تعداد خوشه‌ها (\lr{K}) باید به دقت انجام شود تا بهترین نتیجه حاصل شود.
	
	\item \textbf{استراتژی شبکه‌بندی\LTRfootnote{Grid Strategy}:} در این روش، فضای ورودی به سلول‌های کوچکتری تقسیم می‌شود. آزمایه‌های انتخاب‌شده در هر سلول ذخیره می‌شوند و برای انتخاب آزمایه جدید، فقط سلول‌های مجاور مورد بررسی قرار می‌گیرند. این استراتژی علاوه بر کاهش تعداد محاسبات فاصله، باعث مدیریت بهتر فضای آزمون می‌شود و فضای آزمون به صورت شبکه‌بندی‌شده نگهداری می‌شود. با این حال، این روش به پیاده‌سازی دقیق شبکه‌بندی نیاز دارد و اندازه سلول‌ها باید به دقت تنظیم شود تا بهترین نتیجه حاصل شود.

\end{itemize}

\subsection{اولین پیاده‌سازی روش آزمون تصادفی تطبیقی}
اولین پیاده‌سازی روش آزمون تصادفی تطبیقی روی برنامه‌هایی با ورودی عددی\LTRfootnote{Numerical Input Domain} انجام شد. در این پیاده‌سازی، هر آزمایه که مجموعه‌ای از ورودی‌های عددی بود، به صورت یک نقطه درون یک فضای چندبعدی (تعداد ابعاد برابر با تعداد ورودی‌ها) مدل‌سازی شد. در ادامه، این الگوریتم روی یک مثال ساده بررسی می‌شود.

فرض کنید که یک برنامه به نام \lr{Sum} دارید که دو عدد به عنوان ورودی دریافت کرده و حاصل جمع آن‌ها را برمی‌گرداند. در این الگوریتم، آزمایه‌های این برنامه روی یک فضای دوبعدی به صورت نقطه مدل خواهند شد (برای مثال، آزمایه با ورودی‌های ۱۰ و ۱۵ در فضای ورودی دوبعدی نقطه \lr{(10,15)} را تشکیل می‌دهد) و فاصله بین آن‌ها، همان فاصله اقلیدسی\LTRfootnote{Euclidean distance} بین دو نقطه در نظر گرفته می‌شود.

این روش با روش آزمون تصادفی سنتی روی چند برنامه مختلف با ورودی عددی پیاده‌سازی شد و نتایج نشان داد که این روش از روش آزمون تصادفی سنتی کارایی و عملکرد بهتری دارد.

اما مهم‌ترین مشکل این روش این بود که تنها روی برنامه‌هایی با ورودی عددی قابل پیاده‌سازی بود. با این حال، این مسئله باعث شد که زمینه پژوهشی جدیدی برای محققان ایجاد شود تا راهکاری برای محاسبه فاصله بین دو آزمایه با ورودی‌های غیرعددی\LTRfootnote{Obejctive} ارائه دهند. در اکثر راهکارهای ارائه‌شده، تلاش بر این بوده که هر آزمایه را به عنوان یک نقطه در یک یا چند فضای چندبعدی مدل کنند و سپس با استفاده از محاسبات ریاضی رایج برای محاسبه فاصله در فضاهای چندبعدی، مانند فاصله اقلیدسی، فاصله بین دو نقطه را به دست آورده و به عنوان فاصله بین دو آزمایه ارائه دهند.

\subsection{آخرین ایده پیاده‌سازی ارائه شده برای روش آزمون تصادفی تطبیقی}
آخرین روشی که تاکنون در این حوزه توسط [نام پژوهشگر/منبع] ارائه شده است، شامل روش‌های \lr{WTClustering-ART} و \lr{TFClustering-ART} می‌باشد. در ادامه به بررسی دقیق ساختار و نحوه کارکرد هر کدام از این روش‌ها پرداخته شده است.

\subsubsection{تبدیل فرکانس }
کاهوچی و همکارانش روش‌هایی بر مبنای تبدیل فرکانس\LTRfootnote{Frequency Transform}، که قبلاً برای تبدیل رشته‌ها در جستجوی تشابه رشته‌ها استفاده می‌شد، پیشنهاد کردند. این روش یک رشته با طول تعریف‌شده را با تعداد دفعات هر کاراکتر در رشته به یک بردار فرکانس\LTRfootnote{Frequency Vector} تبدیل می‌کند. تعریف دقیق بردار فرکانس در ادامه آورده شده است.

\begin{itemize}
	\item \textbf{بردار فرکانس:}
	فرض کنید که \(\Sigma = \{m_1, m_2, \dots, m_n\}\) لیست توابع در یک برنامه فرضی باشد و \(s\) ترتیب فراخوانی توابع توسط آزمایه \(t\) باشد. حال بردار فرکانس به صورت 
	\(f(s) = \{f_1, f_2, \dots, f_n\}\)
	 تعریف خواهد شد که \(f_i\) تعداد دفعاتی است که تابع \(m_i\) در ترتیب فراخوانی توابع (\(s\)) حضور دارد.
	
	برای مثال فرض کنید که \(\Sigma = \{a, b, c, d, e\}\) و \(s = abddc\) ترتیب فراخوانی توابع در حین اجرای آزمایه \(t\) باشد. در این وضعیت، تابع \(a\) یک بار، \(b\) یک بار، \(c\) صفر بار، \(d\) دو بار و \(e\) یک بار فراخوانی شده است. در نتیجه:
	\[
	f(s) = \{1, 1, 0, 2, 1\}
	\]
	
	حال با توجه به اینکه هر آزمایه به یک لیست عددی با طول \(n\) (یک نقطه در فضای \(n\) بعدی) تبدیل شده است، اکنون می‌توان به سادگی فاصله بین آزمایه‌ها را با استفاده از محاسبه فاصله بین نقطه‌های متناظر آزمایه‌ها به دست آورد.
	
\end{itemize}

\subsubsection{تبدیل موجک}
اگرچه تبدیل فرکانس می‌تواند به راحتی آزمایه‌های شیء‌گرا را به بردارهایی برای اندازه‌گیری عدم تشابه تبدیل کند، اما فقط بر فرکانس فراخوانی توابع تمرکز می‌کند و به ترتیب فراخوانی توابع اهمیتی نمی‌دهد. از آنجایی که ترتیب واقعی فراخوانی توابع معمولاً بر نتایج اجرا تأثیر می‌گذارد، عدم تشابه محاسبه‌شده رضایت‌بخش نیست.

برای مثال، فرض کنید \(\Sigma = \{a, b, c, d, e\}\) و \(s_1 = acbe\) ترتیب فراخوانی توابع در آزمایه \(t_1\) و \(s_2 = bcae\) ترتیب فراخوانی توابع در آزمایه \(t_2\) باشد. بعد از انجام تبدیل فرکانس، دو بردار فرکانس\\ \(f(s_1) = f(s_2) = \{1, 1, 1, 0, 1\}\) به دست خواهد آمد. فاصله بین آزمایه \(t_1\) و \(t_2\) با توجه به مقایسه بردارهای فرکانس این دو آزمایه صفر است، در حالی که ترتیب فراخوانی توابع در دو آزمایه کاملاً یکسان نیست.

از این رو، روش تبدیل موجک در این مقاله ارائه شد که علاوه بر تعداد فراخوانی هر تابع، به ترتیب فراخوانی توابع نیز تا حدی اهمیت می‌دهد. تبدیل موجک\LTRfootnote{Wavelet Transform} ابزاری ریاضی است که برای تجزیه و تحلیل سیگنال‌ها و داده‌ها در حوزه زمان و فرکانس استفاده می‌شود. در این مقاله، از تبدیل موجک برای اندازه‌گیری عدم تشابه بین تست‌ کیس‌های شیءگرا استفاده می‌شود. این معیار با تجزیه و تحلیل سیگنال‌های مربوط به ویژگی‌های آزمایه‌ها، میزان تفاوت بین آن‌ها را محاسبه می‌کند. در روش
 \lr{ART\_WTClustering} 
 از موجک هار \LTRfootnote{Haar Wavelet} برای مدل‌سازی اطلاعات فرکانس و اطلاعات ترتیب فراخوانی توابع استفاده شده است. در ادامه، معیار تبدیل موجک با مثال توضیح داده شده است.

\begin{itemize}
	\item \textbf{تعریف تبدیل موجک آزمایه:}
فرض کنید \(s = m_1 m_2 \dots m_j\) ترتیب فراخوانی توابع باشد. \(s_1\) یک زیررشته از \(s\) است که حاوی نیمه اول عناصر \(s\) است و \(s_2\) یک زیررشته دیگر از \(s\) است که حاوی نیمه دوم عناصر \(s\) است. تبدیل موجک \(s\) به صورت \(W(s) = [A, B]\) تعریف می‌شود که \(A = f(s)\) و \(B = B_1 - B_2\) که \(B_1 = f(s_1)\) و \(B_2 = f(s_2)\) است.

برای مثال فرض کنید که \(\Sigma = \{a, b, c, d, e\}\) و \(s = abdde\) ترتیب فراخوانی توابع در حین اجرای آزمایه \(t\) باشد. حال مقادیر \(A\) , \(B\) و \(W(s)\) به صورت زیر محاسبه خواهند شد:
\begin{align*}
	A = f(s) &= \{1, 1, 0, 2, 1\} \\
	s_1 = ab \quad & \Rightarrow \quad B_1 = \{1, 1, 0, 0, 0\} \\
	s_2 = dde \quad &\Rightarrow \quad B_2 = \{0, 0, 0, 2, 1\} \\
	B = B_1 - B_2 \quad &\Rightarrow \quad B = \{1, 1, 0, -2, -1\} \\
	W(s) = [A, B] \quad &\Rightarrow \quad W(s) = \left[\{1, 1, 0, 2, 1\}, \{1, 1, 0, -2, -1\}\right]
\end{align*}

\item \textbf{محاسبه فاصله بین آزمایه‌‌ها:}
فرض کنید \(\Sigma = \{m_1, m_2, \dots, m_n\}\) لیست توابع درون یک برنامه فرضی باشد. اگر \(s_1\) ترتیب فراخوانی توابع توسط آزمایه \(t_1\) و \(s_2\) ترتیب فراخوانی توابع توسط آزمایه \(t_2\) باشد، آنگاه \(W(s_1) = [A_1, B_1]\) و \(W(s_2) = [A_2, B_2]\) خواهد بود که \(A_1 = \{A_{11}, A_{12}, \dots, A_{1n}\}\) و \(B_1 = \{B_{11}, B_{12}, \dots, B_{1n}\}\) و \(A_2 = \{A_{21}, A_{22}, \dots, A_{2n}\}\) و \(B_2 = \{B_{21}, B_{22}, \dots, B_{2n}\}\) که فاصله \(WT\_D\) بین این دو آزمایه به صورت زیر محاسبه خواهد شد:
\[
WT\_D(t_1, t_2) = \sqrt{\sum_{i=1}^{n} (A_{1i} - A_{2i})^2} + \sqrt{\sum_{i=1}^{n} (B_{1i} - B_{2i})^2}
\]


\end{itemize}

\subsubsection{تبدیل فرکانس سه‌بخشی}
تا حدی، استفاده مستقیم از تبدیل موجک برای آزمایه‌های شیءگرا نامناسب است. دلیل اصلی این است که، اگرچه دنباله فراخوانی توابع را به دو قسمت تقسیم می‌کند و آنها را حفظ می‌کند، اما تنها تفریق نیمه اول و دوم این دنباله نمی‌تواند تفاوت بین توالی فراخوانی توابع را نمایش دهد. برای پرداختن به این موضوع، در این مقاله پیشنهاد شده است که از تبدیل فرکانس سه‌بخشی \LTRfootnote{Trisection Frequency Conversion (TFC)} استفاده شود. این معیار نه تنها به تعداد فراخوانی هر تابع در حین اجرای آزمایه‌ها توجه دارد بلکه ترتیب فراخوانی توابع در حین اجرای آزمایه‌های مختلف نیز اهمیت دارد.

\begin{itemize}

\item \textbf{تعریف معیار تبدیل فرکانس سه‌بخشی:}
فرض کنید که \(s = m_1 m_2 \dots m_j\) ترتیب فراخوانی توابع در حین اجرای آزمایه \(t\) باشد و \(s_1\) نیمه اول \(s\) و \(s_2\) نیمه دوم \(s\) باشد. معیار تبدیل فرکانس سه‌بخشی برای \(s\) به صورت \(TF(s) = [A, B, C]\) نمایش داده می‌شود که \(A = f(s)\)، \(B = f(s_1)\) و \(C = f(s_2)\) است.

\item \textbf{محاسبه فاصله بین آزمایه‌‌ها:}

فرض کنید \(\Sigma = \{m_1, m_2, \dots, m_n\}\) لیست توابع در یک برنامه فرضی باشد. یک آزمایه \(t_1\) با دنباله فراخوانی توابع \(s_1\) و یک آزمایه \(t_2\) با دنباله فراخوانی توابع \(s_2\) را در نظر بگیرید. فرض کنید\\ \(TF(s_1) = [A_1, B_1, C_1]\) و \(TF(s_2) = [A_2, B_2, C_2]\) که در آن \(A_1 = \{A_{11}, A_{12}, \dots, A_{1n}\}\)، \(B_1 = \{B_{11}, B_{12}, \dots, B_{1n}\}\)، \(C_1 = \{C_{11}, C_{12}, \dots, C_{1n}\}\)، \(A_2 = \{A_{21}, A_{22}, \dots, A_{2n}\}\)، \(B_2 = \{B_{21}, B_{22}, \dots, B_{2n}\}\)، و \(C_2 = \{C_{21}, C_{22}, \dots, C_{2n}\}\). تفاوت ترتیب بین \(s_1\) و \(s_2\) به صورت \(\sum_{i=1}^{j} \left(1 - \delta_{s_{1i} s_{2i}}\right)\) تعریف می‌شود، که \(\delta_{s_{1i} s_{2i}}\) نماد دلتای کرونکر استاندارد است، به طوری که اگر \(s_{1i} = s_{2i}\) باشد آنگاه \(\delta_{s_{1i} s_{2i}} = 1\) و در غیر اینصورت \(\delta_{s_{1i} s_{2i}} = 0\). فاصله \(TFC\)  یا \(TFC\_D\) بین این دو آزمایه به صورت زیر تعریف می‌شود:

\[
TFC\_D(t_1, t_2) = \sqrt{\sum_{i=1}^{n} (A_{1i} - A_{2i})^2} + \sqrt{\sum_{i=1}^{n} (B_{1i} - B_{2i})^2}
\]
\[
+ \sqrt{\sum_{i=1}^{n} (C_{1i} - C_{2i})^2} + \sum_{i=1}^{n} \left(1 - \delta_{s_{1i} s_{2i}}\right)
\quad
\]

\end{itemize}

\subsubsection{مقایسه بین \(TFC\_D\) و \(WT\_D\):}
در اینجا به بررسی تفاوت‌های \(WT\_D\) و \(TFC\_D\) در یک مثال پرداخته شده است. دو آزمایه \(t_1\) و \(t_2\) را در نظر بگیرید که ترتیب فراخوانی توابع توسط این دو آزمایه به صورت \(s_1 = abce\) و \(s_2 = abec\) است که \(s_{11} = ab\)، \(s_{12} = ce\)، \(s_{21} = ab\) و \(s_{22} = ec\) است. در نتیجه:

\begin{align*}
	W(s_1) &= \left[\langle 1, 1, 1, 0, 1 \rangle, \langle 1, 1, -1, 0, -1 \rangle \right] \\
	W(s_2) &= \left[\langle 1, 1, 1, 0, 1 \rangle, \langle 1, 1, -1, 0, -1 \rangle \right]
\end{align*}

است و در نتیجه \({WT\_D}(s_1, s_2)\) برابر است با:

\[
WT\_D(s_1, s_2) = \sqrt{0^2 + 0^2 + 0^2 + 0^2 + 0^2} + \sqrt{0^2 + 0^2 + 0^2 + 0^2 + 0^2} = 0
\]
\textbf{}
از طرفی با توجه به تعریف \(TF(s_i)\) مقادیر \(TF(s_1)\) و \(TF(s_2)\) و \(TFC\_D(s_1, s_2)\) به صورت زیر محاسبه می‌شوند:
\[
TF(s_1) = \left[\langle 1, 1, 1, 0, 1 \rangle, \langle 1, 1, 0, 0, 0 \rangle, \langle 0, 0, 1, 0, 1 \rangle\right]
\]
\[
TF(s_2) = \left[\langle 1, 1, 1, 0, 1 \rangle, \langle 1, 1, 0, 0, 0 \rangle, \langle 0, 0, 1, 0, 1 \rangle\right]
\]

\(TFC\_D(s_1, s_2)\) به صورت زیر محاسبه می‌شود:

\begin{align*}
	TFC\_D(s_1, s_2) &= \sqrt{0^2 + 0^2 + 0^2 + 0^2 + 0^2} + \sqrt{0^2 + 0^2 + 0^2 + 0^2 + 0^2} \\
	&\quad + \sqrt{0^2 + 0^2 + 0^2 + 0^2 + 0^2} + \sum_{i=1}^{j} \left(1 - \delta_{s_{1i}s_{2i}}\right)
\end{align*}

که

\[
\sum_{i=1}^{j} \left(1 - \delta_{s_{1i}s_{2i}}\right) = (1-1) + (1-1)  + (1-0)  + (1-0) = 2
\]

بنابراین:

\[
TFC\_D(s_1, s_2) = 0 + 0 + 0 + 2 = 2 
\]

همانطور که مشاهده کردید،‌ فاصله \(TFC\) در این مثال نسبت به فاصله \(ٌُWT\)  به ترتیب فراخوانی توابع توسط آزمایه‌ها اهمیت بیشتری می دهد.


\newpage

	\begin{tikzpicture}[node distance=2.5cm]
		
		\node (start) [startstop] {\rl{به صورت تصادفی اولین مورد آزمایشی شئ‌گرا را ایجاد کرده و اجرا کنید}};
		\node (decision) [decision, below of=start, yshift=-1cm] {\rl{شرط خاتمه}};
		\node (output) [startstop, right of=decision, xshift=4cm] {\rl{خروجی آزمایه‌های تولید شده}};
		\node (process1) [process, below of=decision, yshift=-1cm] {\rl{اضافه کردن این آزمایه به مجموعه آزمایه‌های انتخاب شده در مراحل قبلی الگوریتم}};
		\node (process2) [process, below of=process1, yshift=-1cm] {\rl{تولید ۱۰ آزمایه شئ‌گرا جدید به عنوان مجموعه کاندید}};
		
		\node (process3) [process, below of=process2, yshift=-1cm, xshift=0.5cm, text width=7cm] {\rl{خوشه‌بندی مجموعه آزمایه‌های از قبل انتخاب شده به \rl{K} خوشه}};
		\node (process4) [process, below of=process3, yshift=-0.5cm] {\rl{تعیین نماینده هر خوشه برای ارزیابی آزمایه‌های کاندید}};
		\node (process5) [process, below of=process4, yshift=-0.5cm] {Select the candidate which has the smallest distance with the subset};
		
		\draw [arrow] (start) -- (decision);
		\draw [arrow] (decision) -- node[anchor=east] {No} (process1);
		\draw [arrow] (decision) -- node[anchor=north] {Yes} (output);
		\draw [arrow] (process1) -- (process2);
		\draw [arrow] (process2) -- (process3);
		\draw [arrow] (process3) -- (process4);
		\draw [arrow] (process4) -- (process5);
%		\draw [arrow] (process5.east) -| ++(4,0) |- (decision.east);
		
		% Adding labels ①, ②, ③
%		\node[draw=none, fill=none] at ($(process2)!0.5!(process3)$) {\textcircled{1}};
%		\node[draw=none, fill=none] at ($(process3)!0.5!(process4)$) {\textcircled{2}};
%		\node[draw=none, fill=none] at ($(process4)!0.5!(process5)$) {\textcircled{3}};
		
	\end{tikzpicture}



\subsection{روش‌های مختلف انتخاب آزمایه بر اساس فاصله}


\subsection{نقطه اشتراک اکثر روش‌های پیاده‌سازی الگوریتم آزمون تصادفی تطبیقی}

\section{روش تقسیم‌بندی فضای ورودی}

\subsection{فرآیند تولید آزمایه توسط روش تقسیم‌بندی فضای ورودی}

%===============================================================================================================




%
%
%
%\newpage
%\section{مقدمه}
%هدف از این فصل که با عنوان‌های  «مروری بر ادبیات موضوع%
%\LTRfootnote{Literature Review}»،
%«مروری بر منابع» و یا «مروری بر پیشینه تحقیق%
%\LTRfootnote{Background Research}»
%معرفی می‌شود، بررسی و طبقه‌بندی یافته‌های تحقیقات دیگر محققان در سطح دنیا و تعیین و شناسایی خلأهای تحقیقاتی است. آنچه را که تحقیق شما به دانش موجود اضافه می‌کند، مشخص کنید. طرح پیشینه تحقیق%
%\LTRfootnote{Background Information}
%یک مرور محققانه است و تا آنجا باید پیش برود که پیش‌زمینهٔ تاریخی مناسبی از تحقیق را بیان کند و جایگاه تحقیق فعلی را در میان آثار پیشین نشان دهد. برای این منظور منابع مرتبط با تحقیق را بررسی کنید، البته نه آنچنان گسترده که کل پیشینه تاریخی بحث را در برگیرد. برای نوشتن این بخش:
%\begin{itemize}
%	\item
%	دانستنی‌های موجود و پیش‌زمینهٔ تاریخی و وضعیت کنونی موضوع را چنان بیان کنید که خواننده بدون مراجعه به منابع پیشین، نتایج حاصل از مطالعات قبلی را درک و ارزیابی کند.
%	\item
%	نشان دهید که بر موضوع احاطه دارید. پرسش تحقیق را همراه بحث و جدل‌ها و مسائل مطرح شده بیان کنید و مهم‌ترین تحقیق‌های انجام شده در این زمینه را معرفی نمائید.
%	\item
%	ابتدا مطالب عمومی‌تر و سپس پژوهش‌های مشابه با کار خود را معرفی کرده و نشان دهید که تحقیق شما از چه جنبه‌ای با کار دیگران تشابه یا تفاوت دارد.
%	\item
%	اگر کارهای قبلی را خلاصه کرده‌اید، از پرداختن به جزئیات غیرضروری بپرهیزید. در عوض، بر یافته‌ها و مسائل روش‌شناختی مرتبط و نتایج اصلی تأکید کنید و اگر بررسی‌ها و منابع مروری عمومی دربارهٔ موضوع موجود است، خواننده را به آنها ارجاع دهید.
%\end{itemize}
%
%\section{تعاریف، اصول و مبانی نظری}
%این قسمت ارائهٔ خلاصه‌ای از دانش کلاسیک موضوع است. این بخش الزامی نیست و بستگی به نظر استاد راهنما دارد.
%
%\section{مروری بر ادبیات موضوع}
%در این قسمت باید به کارهای مشابه دیگران در گذشته اشاره کرد و وزن بیشتر این قسمت بهتر است به مقالات ژورنالی سال‌های اخیر (۲ تا ۳ سال) تخصیص داده شود. به نتایج کارهای دیگران با ذکر دقیق مراجع باید اشاره شده و جایگاه و تفاوت تحقیق شما نیز با کارهای دیگران مشخص شود. استفاده از مقالات ژورنال‌های معتبر در دو یا سه سال اخیر، می‌تواند به اعتبار کار شما بیافزاید.
%
%\section{نتیجه‌گیری}
%‌در نتیجه‌گیری آخر این فصل، با توجه به بررسی انجام شده بر روی مراجع تحقیق، بخش‌های قابل گسترش و تحقیق در آن حیطه و چشم‌اندازهای تحقیق مورد بررسی قرار می‌گیرند.	در برخی از تحقیقات، نتیجه نهایی فصل روش تحقیق، ارائهٔ یک چارچوب کار تحقیقی 
%\lr{(research framework)}
است.