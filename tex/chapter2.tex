% !TeX root=../main.tex
\chapter{پیشینه پژوهش}\label{chapter2}
%\thispagestyle{empty} 
\section{آزمون نرم‌افزار و اهمیت آن}

آزمون نرم‌افزار یکی از مراحل حیاتی در فرآیند توسعه نرم‌افزار است که به اطمینان از کیفیت و عملکرد صحیح نرم‌افزار در شرایط مختلف کمک می‌کند. اهمیت آزمون نرم‌افزار از چند جنبه قابل بررسی است:

\begin{itemize}
	\item \textbf{کشف خطا‌ها و مشکلات}
	
	 آزمون نرم‌افزار به شناسایی و رفع خطاها و اشکالات نرم‌افزاری قبل از اینکه نرم‌افزار به دست کاربران برسد، کمک می‌کند. این کار از بروز مشکلات جدی و نارضایتی کاربران جلوگیری می‌کند.
	\item \textbf{افزایش اعتماد به کیفیت نرم‌افزار}
	
	 با انجام آزمون‌های دقیق و کامل، می‌توان اطمینان حاصل کرد که نرم‌افزار به درستی و با کیفیت بالا کار می‌کند. این اعتماد برای مشتریان و کاربران نهایی بسیار مهم است.
	\item \textbf{کاهش هزینه‌ها}
	
	 شناسایی و رفع مشکلات در مراحل اولیه توسعه نرم‌افزار بسیار کم‌هزینه‌تر از رفع آنها پس از انتشار نرم‌افزار است. آزمون مؤثر نرم‌افزار می‌تواند هزینه‌های نگهداری و پشتیبانی را به میزان قابل توجهی کاهش دهد.
	\item \textbf{اطمینان از عملکرد صحیح نرم‌افزار در شرایط مختلف}
	
	 آزمون نرم‌افزار تضمین می‌کند که نرم‌افزار در شرایط مختلف (مانند سیستم‌عامل‌های متفاوت، نسخه‌های مختلف مرورگرها و غیره) به درستی عمل می‌کند.
	\item \textbf{مستندسازی و درک بهتر سیستم}
	
	 فرآیند آزمون شامل نوشتن آزمایه‌ها و مستندسازی آن‌ها است که به توسعه‌دهندگان کمک می‌کند تا درک بهتری از سیستم داشته باشند و در آینده به راحتی بتوانند تغییرات مورد نیاز را اعمال کنند.
\end{itemize}

\section{تولید آزمایه به صورت خودکار}
تولید خودکار آزمایه 
\LTRfootnote{Testcase}
به معنای ایجاد سناریوهای آزمون به صورت خودکار، بدون نیاز به دخالت دستی است. در این روش آزمونگر از تکنیک‌ها و ابزارهای ویژه‌ای استفاده می‌کند تا سناریوهای متنوعی برای بررسی عملکرد سیستم تحت آزمون
\LTRfootnote{System Under Test}
 ایجاد کند. مزایای این روش عبارت‌اند از:
\begin{itemize}
	\item \textbf{پوشش گسترده‌تر آزمون}
	
	 تولید خودکار آزمایه‌ها، مواردی را پوشش می‌دهد که ممکن است در آزمون‌های دستی نادیده گرفته شوند. این امر به ویژه در آزمون نرم‌افزارهای پیچیده و بزرگ اهمیت بیشتری دارد.
	\item \textbf{افزایش کارایی آزمون}
	
	 با خودکارسازی فرآیند تولید آزمایه‌ها، می‌توان تعداد زیادی آزمایه در مدت زمان کوتاهی ایجاد کرد، که این کارایی در فازهای توسعه و نگهداری نرم‌افزار بسیار مفید است.
	\item \textbf{کشف خطاهای ناشناخته}
	
	 تولید خودکار آزمایه‌ها به شناسایی خطاهایی کمک می‌کند که ممکن است در سناریوهای پیش‌بینی‌نشده رخ دهند. آزمون‌های تصادفی به خصوص در این زمینه بسیار مؤثر هستند.
	\item \textbf{کاهش دخالت انسانی}
	
	 خودکارسازی تولید آزمایه‌ها باعث کاهش خطاهای انسانی می‌شود و دقت و اطمینان آزمون‌ها را افزایش می‌دهد.
\end{itemize}

\section{آزمون تصادفی}
آزمون تصادفی
\cite{hamlet1994random}
 یک روش آزمون نرم‌افزار جعبه سیاه
\LTRfootnote{Black Box Testing}\cite{nidhra2012black}
  است که در آن سیستم تحت آزمون با ورودی‌های تولید شده به صورت تصادفی ارزیابی می‌شود. هدف اصلی آزمون تصادفی، شناسایی اشکالات نرم‌افزار و اطمینان از کیفیت و استحکام نرم‌افزار در مواجهه با انواع مختلف سناریوهای ورودی است. تاکنون از روش آزمون تصادفی برای آزمون سیستم‌های مختلفی همچون برنامه‌های سیستم‌عامل مَک~\LTRfootnote{macos}\cite{miller2006empirical}
 ، سیستم‌های نرم‌افزاری توزیع‌شده~\LTRfootnote{Embedded Software Systems}\cite{regehr2005random}
  ، سیستم‌های پایگاه‌داده اس‌.کیو.ال~\LTRfootnote{SQL}\cite{bati2007genetic}
  و برنامه‌های اندرویدی~\LTRfootnote{Android Applications}\cite{muangsiri2017random}
استفاده شده است.
\subsection{فرآیند تولید آزمایه توسط آزمون تصادفی}

فرآیند تولید آزمایه به صورت خودکار توسط روش آزمون تصادفی را می‌توان به صورت زیر ترسیم کرد:

\begin{enumerate}
	\item \textbf{تعریف فضای ورودی\LTRfootnote{Input Domain}}
	
	 در این مرحله محدوده و نوع ورودی‌هایی که نرم‌افزار می‌تواند بپذیرد، مشخص می‌گردد. این مرحله شامل تعیین دامنه‌های ورودی و محدودیت‌ها برای اطمینان از صحت آزمایه‌های تولید شده است.
	\item \textbf{تولید آزمایه}
	
	 مجموعه‌ای از مقادیر ورودی به صورت تصادفی در داخل فضای ورودی تعریف شده، تولید می‌شود. این ورودی‌ها باید طیف گسترده‌ای از سناریوهای ممکن را پوشش دهند تا احتمال کشف اشکالات سیستم تحت آزمون افزایش یابد.
	\item \textbf{اجرای آزمایه‌ها}
	
	 نرم‌افزار با استفاده از ورودی‌های تصادفی تولید شده اجرا شده و رفتار و خروجی‌های آن برای هر گونه ناهنجاری یا نتایج غیرمنتظره نظارت می‌شود.
	\item \textbf{ارزیابی خروجی‌ها}
	
	 خروجی‌های واقعی نرم‌افزار با خروجی‌های مورد انتظار (در صورت موجود بودن) مقایسه می‌شوند تا هر گونه تفاوت شناسایی گردد. در مواردی که خروجی مورد انتظار از پیش تعیین نشده است، می‌توان از روش‌های اکتشافی یا اوراکل‌ها~\LTRfootnote{Oracle}\cite{nardi2015survey}
	 برای ارزیابی درستی رفتار سیستم تحت آزمون استفاده کرد.
	\item \textbf{شناسایی و تحلیل اشکالات}
	
	 هر گونه خطا و مغایرت خروجی سیستم با خروجی مورد انتظار که در حین آزمون شناسایی شود، تحلیل می‌گردد تا علل زیربنایی آن تشخیص داده شود.
	 
\end{enumerate}

\subsection{مزایای آزمون تصادفی}
آزمون تصادفی چندین مزیت دارد که آن را به یک تکنیک ارزشمند در آزمون نرم‌افزار تبدیل می‌کند:
\begin{itemize}
	\item \textbf{پوشش گسترده}
	
	با تولید مجموعه‌ای متنوع از ورودی‌های تصادفی، آزمون تصادفی می‌تواند طیف گسترده‌ای از سناریوهای ورودی را پوشش دهد. این امر احتمال کشف اشکالات نادر یا غیرمنتظره‌ای که ممکن است از طریق دیگر روش‌های آزمون نرم‌افزار شناسایی نشوند را افزایش می‌دهد.
	\item \textbf{سادگی}
	
	 این روش به سادگی قابل پیاده‌سازی است و نیازی به دانش عمیق از ساختار داخلی نرم‌افزار ندارد و آزمایه‌ها می‌توانند به صورت خودکار و بدون تلاش دستی، به صورت نامحدود تولید شوند.
	\item \textbf{خودکارسازی}
	
	 آزمون تصادفی می‌تواند به طور کامل خودکار شود و امکان آزمون پیوسته و بدون نیاز به نظارت انسانی را فراهم کند. این امر نیاز به دخالت انسانی را کاهش می‌دهد.

\end{itemize}

\subsection{معایب آزمون تصادفی}
با وجود مزایای آن، آزمون تصادفی چندین محدودیت دارد که می‌تواند بر اثربخشی آن تأثیر بگذارد:
\begin{itemize}
	\item \textbf{تکرارپذیری}
	
	آزمون تصادفی ممکن است موارد آزمون تکراری تولید کند که ارزش افزوده زیادی ندارند. تکرارپذیری موارد آزمون می‌تواند منجر به حجم بالای آزمون‌ها با نرخ شناسایی اشکال پایین شود.
	\item \textbf{ناکارآمدی}
	
	 این روش می‌تواند از نظر زمان و منابع محاسباتی ناکارآمد باشد. بسیاری از ورودی‌های تولید شده ممکن است موارد آزمون معناداری را تولید نکنند، که منجر به هدر رفتن تلاش‌ها و منابع استفاده شده جهت آزمون می‌شود.
	\item \textbf{تمرکز محدود}
	
	 آزمون تصادفی نواحی ورودی خاص یا نقاط خرابی بحرانی را اولویت‌بندی نمی‌کند. بنابراین، ممکن است اشکالات مهمی که در نواحی کمتر آزمون شده متمرکز شده‌اند را نادیده بگیرد.
\end{itemize}

\section{آزمون تصادفی تطبیقی}
آزمون تصادفی تطبیقی
 \cite{huang2019survey}
   با هدف بهبود آزمون تصادفی سنتی به وجود آمد و به ناکارآمدی‌ها و محدودیت‌های آن پرداخت. مفهوم آزمون تصادفی تطبیقی برای افزایش قابلیت‌های شناسایی اشکال آزمون تصادفی، با استفاده از استراتژی‌های تطبیقی که انتخاب موارد آزمون را هدایت می‌کنند، معرفی شد. آزمون تصادفی تطبیقی هدف دارد تا نرخ شناسایی اشکال را با حفظ مزایای سادگی و خودکارسازی آزمون تصادفی، بیشتر کند.

\subsection{فرضیه اصلی آزمون تصادفی تطبیقی}

توسعه آزمون تصادفی تطبیقی به دلیل نیاز به کاهش تکرارپذیری و ناکارآمدی مرتبط با تولید موارد آزمون به صورت تصادفی خالص به وجود آمد. محققان مشاهده کردند که اشکالات نرم‌افزار تمایل دارند در برخی نواحی فضای ورودی متمرکز شوند~\cite{white1980domain}\cite{ammann1988data}\cite{finelli1991nasa}\cite{bishopvariation}\cite{schneckenburger2007towards}
 و \textbf{نقاط شکست درون دامنه ورودی به صورت ناحیه‌ای هستند و تمایل به پیوسته بودن دارند}.
به عبارت دیگر، اگر نواحی شکست به‌صورت پیوسته باشند، نتیجه می‌شود که نواحی غیرشکست نیز باید در سراسر دامنه ورودی مجاور یکدیگر باشند. به‌طور خاص: اگر یک آزمایه \lr{tc} یک ورودی باعث شکست باشد، احتمال بالایی وجود دارد که همسایگان آن نیز باعث شکست شوند؛ به‌طور مشابه، اگر \lr{tc} باعث شکست نشود، احتمال بالایی وجود دارد که همسایگان آن نیز باعث شکست نشوند. به‌عبارت دیگر، یک ورودی برنامه که از ورودی‌های غیرشکست دور است، ممکن است احتمال بیشتری برای ایجاد شکست نسبت به آزمایه‌های همسایه داشته باشد. از طرف دیگر، یک ورودی که به ورودی‌های باعث شکست نزدیک است، به احتمال زیاد باعث شکست خواهد شد، اما احتمال بالایی وجود دارد که ناحیه شکست شناسایی‌شده توسط این ورودی، قبلاً توسط ورودی‌های باعث شکست همسایه شناسایی شده باشد و شناسایی مجدد آن سودی نخواهد داشت.

 در نتیجه هر چه تراکم آزمایه‌ها روی دامنه ورودی بیشتر باشد، احتمال کشف خطای جدید بیشتر خواهد بود. آزمون تصادفی تطبیقی از این مشاهده بهره می‌برد و از بازخورد موارد آزمون قبلی برای هدایت تولید موارد آزمون بعدی استفاده می‌کند. به طور کلی، آزمون تصادفی تطبیقی، آزمون تصادفی سنتی را با استفاده از تکنیک‌هایی که توزیع یکنواخت‌تری از موارد آزمون را در سراسر فضای ورودی تضمین می‌کنند، تقویت می‌کند. اصل کلیدی روش آزمون تصادفی تطبیقی این است که حداکثر تنوع موارد آزمون را به دست آورد و به این ترتیب، احتمال شناسایی شکست‌های جدید را افزایش دهد\cite{chen2010adaptive}.

\subsection{فرآیند تولید آزمایه توسط آزمون تصادفی تطبیقی}

فرآیند تولید آزمایه به صورت خودکار توسط روش آزمون تصادفی تطبیقی را می‌توان به صورت زیر ترسیم کرد:
\begin{enumerate}
	\item \textbf{تولید مجموعه کاندید\LTRfootnote{Candidate Set}}
	
	 در این مرحله ابتدایی، یک مجموعه‌ای از آزمایه‌ها با استفاده از روش آزمون تصادفی تولید می‌شود. این آزمایه‌ها به صورت تصادفی روی فضای ورودی تعریف شده از نرم‌افزار ایجاد می‌شوند.
	 
	\item \textbf{انتخاب آزمایه}
	
	 از مجموعه کاندید تولید شده، یک آزمایه بر اساس یک استراتژی خاص که منحصراً به روش آزمون تصادفی تطبیقی مربوط است، انتخاب می‌شود. این استراتژی معمولاً به منظور به حداکثر رساندن پراکندگی آزمایه‌ها در فضای ورودی عمل می‌کند. با انتخاب آزمایه‌هایی که به طور گسترده‌تری پراکنده شده‌اند، آزمون تصادفی تطبیقی سعی دارد که احتمال کشف شکست‌ها را نسبت به آزمون تصادفی سنتی افزایش دهد. اکثر این استراتژی‌ها در ابتدا یک معیار فاصله بین آزمایه‌ها تعریف کرده‌اند و سپس با توجه به این معیار، سعی بر انتخاب آزمایه‌هایی از بین مجموعه آزمایه‌های کاندید داشته‌اند که بیشترین فاصله را با مجموعه آزمایه‌های انتخاب‌شده قبلی\LTRfootnote{Executed Set} داشته باشند.
	 
	\begin{itemize}
		\item \textbf{روش‌های مختلف انتخاب آزمایه بر اساس فاصله}
		
		تاکنون روش‌های مختلفی برای انتخاب آزمایه با توجه به فاصله‌های به دست آمده بین مجموعه آزمایه‌های کاندید و مجموعه آزمایه‌های انتخاب‌شده در مراحل قبلی الگوریتم آزمون تصادفی تطبیقی ارائه شده است. در ادامه به بررسی مهم‌ترین و مطرح‌ترین این روش‌ها پرداخته شده است:
		
		\begin{itemize}
			\item \textbf{بیشترین-کمترین فاصله\LTRfootnote{max-min distance}}
			 
			در این روش \cite{chen2001proportional} به ازای هر آزمایه درون مجموعه کاندید، فاصله با آزمایه‌های قبلی انتخاب‌شده محاسبه می‌شود و «کمترین فاصله» بین آن آزمایه کاندید و مجموعه آزمایه‌های انتخاب‌شده قبلی محاسبه می‌شود. سپس آزمایه‌ کاندیدی انتخاب می‌شود که مقدار «کمترین فاصله» آن از بقیه آزمایه‌های کاندید بیشتر باشد.
			
			\item \textbf{بیشترین-مجموع فاصله\LTRfootnote{max-sum distance}}
			 
			در این روش \cite{zhou2021cost} به ازای هر آزمایه درون مجموعه کاندید، «مجموع فاصله» با آزمایه‌های قبلی انتخاب‌شده محاسبه می‌شود و سپس آزمایه‌ای انتخاب می‌شود که مقدار «مجموع فاصله» آن از بقیه آزمایه‌های درون مجموعه کاندید بیشتر باشد.
		\end{itemize}
		
	\end{itemize}
	
	\item \textbf{تکرار}
	
	 آزمایه انتخاب شده به مجموعه آزمایه‌های انتخاب شده اضافه می‌شود و فرآیند تولید یک مجموعه کاندید جدید و انتخاب یک آزمایه ادامه می‌یابد تا زمانی که شرط خاتمه ارضاء شود که برای مثال شرط خاتمه می‌تواند رسیدن به تعداد مشخصی آزمایه یا کشف شکست درون سیستم تحت آزمون باشد.
	 
\end{enumerate}
با دنبال کردن این مراحل، آزمون تصادفی تطبیقی تلاش می‌کند تا با تمرکز بر توزیع یکنواخت‌تر آزمایه‌ها، قابلیت کشف خطا را در مقایسه با آزمون تصادفی سنتی بهبود بخشد.

\subsection{مزایای آزمون تصادفی تطبیقی}
آزمون تصادفی تطبیقی چندین مزیت دارد که آن را به جایگزینی برتر برای آزمون تصادفی سنتی تبدیل می‌کند\cite{johansson2023comparison}. در ادامه به برخی از این مزیت‌ها اشاره شده است:
\begin{itemize}
	\item \textbf{کاهش تکرارپذیری}
	
	 آزمون تصادفی تطبیقی با تولید موارد آزمون متنوع تکرارپذیری را کاهش می‌دهد. این امر ارزش هر مورد آزمون را به حداکثر می‌رساند و تلاش‌های بیهوده آزمون را به حداقل می‌رساند.
	\item \textbf{افزایش کارایی و نرخ شناسایی اشکال بالاتر:}‌ به دنبال کاهش تکرارپذیری موارد آزمون، کارایی روش آزمون تصادفی تطبیقی افزایش می‌یابد و فرآیند آزمون را بهبود می‌بخشد، که این خود منجر به نرخ شناسایی اشکال بالاتر با تعداد آزمایه کمتر می‌شود.
	\item \textbf{پوشش متعادل}
	
	 روش آزمون تصادفی تطبیقی، پوشش متعادل‌تری از فضای ورودی را به دست می‌آورد و خطر نادیده گرفتن نواحی مهم را کاهش می‌دهد. این پوشش جامع، استحکام کلی نرم‌افزار را افزایش می‌دهد.
	\item \textbf{بهینه‌سازی منابع}
	
	 با بهبود کارایی تولید موارد آزمون، آزمون تصادفی تطبیقی از منابع محاسباتی و زمانی بهینه استفاده می‌کند. این امر آزمون تصادفی تطبیقی را به یک راه‌حل عملی و مقیاس‌پذیر برای آزمون نرم‌افزار در مقیاس بزرگ تبدیل می‌کند.
\end{itemize}

\subsection{سربار محاسباتی پیاده‌سازی آزمون تصادفی تطبیقی}
در مرحله انتخاب آزمایه از فرآیند پیاده‌سازی روش آزمون تصادفی تطبیقی، لازم است که فاصله بین هر آزمایه درون مجموعه کاندید و هر آزمایه درون مجموعه آزمایه‌های انتخاب‌شده در مراحل قبلی محاسبه شود. آزمایه‌ای که بیشترین فاصله را با مجموعه آزمایه‌های انتخاب‌شده دارد، انتخاب می‌شود. در این مرحله، باید (تعداد آزمایه‌های درون مجموعه کاندید × تعداد آزمایه‌های درون مجموعه آزمایه‌های انتخاب‌شده) بار فاصله محاسبه شود. با افزایش تعداد اعضای مجموعه آزمایه‌های انتخاب‌شده در هر بار تکرار فرآیند، سربار محاسباتی الگوریتم آزمون تصادفی تطبیقی افزایش می‌یابد. همچنین، تعداد اعضای درون مجموعه کاندید نیز تأثیر مستقیمی بر افزایش سربار محاسباتی الگوریتم دارد. در ادامه، استراتژی‌هایی که تاکنون برای کاهش اندازه مجموعه کاندید، کاهش تعداد آزمایه‌های درون مجموعه آزمایه‌های انتخاب‌شده در مراحل قبلی الگوریتم، و در نهایت کاهش تعداد محاسبات فاصله ارائه شده‌اند، شرح داده می‌شود.

\subsubsection{اندازه مجموعه کاندید ثابت}
اولین و پرکاربردترین استراتژی پیاده‌سازی الگوریتم آزمون تصادفی تطبیقی، استراتژی "انتخاب آزمایه از مجموعه کاندید با اندازه ثابت\LTRfootnote{Fixed Sized Candidate Set (FSCS)}\cite{chen2001proportional} است. در این استراتژی، اندازه مجموعه کاندید در کل روند اجرای الگوریتم ثابت در نظر گرفته می‌شود. بهترین مقدار برای اندازه مجموعه کاندید طبق پژوهش \cite{chen2005adaptive} برابر با ۱۰ اعلام شده است. البته، هر چه اندازه مجموعه کاندید را افزایش دهیم، این امر می‌تواند بر اثربخشی آزمایه‌های نهایی تأثیر داشته باشد. اما بر اساس این پژوهش، هنگامی که اندازه مجموعه کاندید از ۱۰ بیشتر باشد، میزان افزایش اثربخشی مجموعه آزمایه‌ها خیلی قابل توجه نیست.

\subsubsection{بزرگ شدن فضای آزمون در آزمون تصادفی تطبیقی}
یکی از چالش‌های اصلی و مهم در آزمون تصادفی تطبیقی، بزرگ شدن فضای آزمون است. با افزایش تعداد آزمایه‌های انتخاب شده، محاسبه فاصله هر آزمایه جدید با آزمایه‌های قبلی زمان‌بر و ناکارآمد می‌شود. این مسئله باعث افزایش پیچیدگی محاسباتی و کاهش کارایی فرآیند آزمون می‌شود. برای مقابله با این مشکل، استراتژی‌های مختلفی ارائه شده‌اند که هدف آن‌ها کاهش فضای آزمون و بهبود کارایی تولید آزمایه‌ها است.
\begin{itemize}
	\item \textbf{استراتژی فراموشی\LTRfootnote{Forgetting Strategy}}
	
	 استراتژی فراموشی \cite{chan2006forgetting}\cite{mao2017out} به منظور مدیریت فضای آزمون و جلوگیری از بزرگ شدن بیش از حد آن استفاده می‌شود. در این روش، زمانی که مجموعه آزمایه‌های از قبل انتخاب‌شده به توزیع یکنواخت مناسبی می‌رسند، این مجموعه پاک می‌شود. با این کار، فقط آزمایه‌های جدیدتر و مرتبط‌تر در فرآیند محاسبه فاصله‌ها لحاظ می‌شوند. در این استراتژی با پاک کردن آزمایه‌های قدیمی‌تر، حجم داده‌های مورد نیاز برای محاسبه فاصله‌ها کاهش می‌یابد و محاسبات سریع‌تر و کارآمدتر انجام می‌شود. البته، احتمال از دست رفتن اطلاعات مفید از آزمایه‌های قبلی وجود دارد و همچنین معیارهای فراموشی باید به دقت تنظیم شوند تا بهترین نتیجه حاصل شود.
	
	\item \textbf{خوشه‌بندی \lr{K}-مرکز\LTRfootnote{K-means Clustering Strategy}}
	
	 خوشه‌بندی \lr{K}-مرکز \cite{burkardt2009k} یکی دیگر از استراتژی‌های کاهش فضای آزمون است. در این روش\cite{chen2021novel}، آزمایه‌های انتخاب‌شده به خوشه‌هایی تقسیم می‌شوند و هر خوشه با یک نماینده (میانگین) که مرکز خوشه است، مشخص می‌شود. برای انتخاب آزمایه جدید، فاصله بین آزمایه‌های کاندید و نمایندگان خوشه‌ها محاسبه می‌شود. این استراتژی علاوه بر کاهش تعداد محاسبات فاصله، باعث مدیریت بهتر فضای آزمون می‌شود و فضای آزمون به صورت خوشه‌بندی‌شده نگهداری می‌شود. با این حال، این روش ممکن است پیچیدگی اجرای الگوریتم را افزایش دهد و تعیین تعداد خوشه‌ها (\lr{K}) باید به دقت انجام شود تا بهترین نتیجه حاصل شود.
	مقدار \lr{K} یک درصد ثابت از کل تعداد آزمایه‌هایی است که تا آن لحظه انتخاب شده‌اند و بهترین مقدار برای \lr{K} بین ۱۰ تا ۲۰ درصد از تعداد کل آزمایه‌های انتخاب‌شده، اعلام شده است.
	
	\item \textbf{استراتژی شبکه‌بندی\LTRfootnote{Grid Strategy}}
	
	 در این روش\cite{chow2013art}، فضای ورودی به سلول‌های کوچکتری تقسیم می‌شود. آزمایه‌های انتخاب‌شده در هر سلول ذخیره می‌شوند و برای انتخاب آزمایه جدید، فقط سلول‌های مجاور مورد بررسی قرار می‌گیرند. این استراتژی علاوه بر کاهش تعداد محاسبات فاصله، باعث مدیریت بهتر فضای آزمون می‌شود و فضای آزمون به صورت شبکه‌بندی‌شده نگهداری می‌شود. با این حال، این روش به پیاده‌سازی دقیق شبکه‌بندی نیاز دارد و اندازه سلول‌ها باید به دقت تنظیم شود تا بهترین نتیجه حاصل شود.

\end{itemize}

\subsection{اولین پیاده‌سازی روش آزمون تصادفی تطبیقی}
اولین پیاده‌سازی روش آزمون تصادفی تطبیقی \cite{chen2001proportional} روی برنامه‌هایی با ورودی عددی\LTRfootnote{Numerical Input Domain} انجام شد. در این پیاده‌سازی، هر آزمایه که مجموعه‌ای از ورودی‌های عددی بود، به صورت یک نقطه درون یک فضای چندبعدی (تعداد ابعاد برابر با تعداد ورودی‌ها) نگاشت می‌شد سپس برای محاسبه فاصله بین آزمایه‌ها، فاصله نقاط متناظر آن دو آزمایه محاسبه می‌شد. در ادامه، این الگوریتم روی یک مثال ساده بررسی می‌شود.

فرض کنید که یک برنامه به نام \lr{Sum} دارید که دو عدد به عنوان ورودی دریافت کرده و حاصل جمع آن‌ها را برمی‌گرداند. در این الگوریتم، آزمایه‌های این برنامه روی یک فضای دوبعدی به صورت نقطه نگاشت خواهند شد (برای مثال، آزمایه با ورودی‌های ۱۰ و ۱۵ در فضای ورودی دوبعدی نقطه \rl{(15,10)} را تشکیل می‌دهد) و فاصله بین آن‌ها، همان فاصله اقلیدسی\LTRfootnote{Euclidean distance} بین دو نقطه در نظر گرفته می‌شود.

این روش با روش آزمون تصادفی سنتی روی چند برنامه مختلف با ورودی عددی پیاده‌سازی شد و نتایج نشان داد که این روش از روش آزمون تصادفی سنتی کارایی و عملکرد بهتری دارد.

اما مهم‌ترین مشکل این روش این بود که تنها روی برنامه‌هایی با ورودی عددی قابل پیاده‌سازی بود. با این حال، این مسئله باعث شد که زمینه پژوهشی جدیدی برای محققان ایجاد شود تا راهکاری برای محاسبه فاصله بین دو آزمایه با ورودی‌های غیرعددی\LTRfootnote{Obejctive} ارائه دهند. در اکثر راهکارهای ارائه‌شده، تلاش بر این بوده که هر آزمایه را به عنوان یک نقطه در یک یا چند فضای چندبعدی نگاشت کنند و سپس با استفاده از محاسبات ریاضی رایج برای محاسبه فاصله در فضاهای چندبعدی، مانند فاصله اقلیدسی، فاصله بین دو نقطه را به دست آورده و به عنوان فاصله بین دو آزمایه ارائه دهند.

\subsection{آخرین ایده پیاده‌سازی ارائه شده برای روش آزمون تصادفی تطبیقی}

آخرین پژوهشی که تاکنون روی ایده پیاده‌سازی روش آزمون تصادفی تطبیقی انجام شده است، روش پیاده‌سازی آزمون تصادفی تطبیقی با استفاده از استراتژی خوشه‌بندی \lr{K}-مرکز می‌باشد که توسط چِن و همکارانش در سال 2021 ارائه شده است. در این پژوهش، روش‌های \lr{WTClustering-ART} و \lr{TFClustering-ART} برای پیاده‌سازی آزمون تصادفی تطبیقی ارائه شده‌اند که نسبت به سایر روش‌های پیشین پیاده‌سازی آزمون تصادفی تطبیقی، عملکرد بهتری روی معیارهای ارزیابی قدرت تشخیص شکست از خود نشان داده‌اند. در ادامه، ساختار و نحوه کارکرد هر یک از این روش‌ها به‌صورت دقیق بررسی خواهد شد.

\subsubsection{تبدیل فرکانس }
کاهوچی و همکارانش \cite{kahveci2001efficient} روش‌هایی بر مبنای تبدیل فرکانس\LTRfootnote{Frequency Transform}، که قبلاً برای تبدیل رشته‌ها در جستجوی تشابه رشته‌ها استفاده می‌شد، پیشنهاد کردند. این روش یک رشته با طول تعریف‌شده را با تعداد دفعات هر کاراکتر در رشته به یک بردار فرکانس\LTRfootnote{Frequency Vector} تبدیل می‌کند. چِن و همکارانش از ایده این پژوهش برای تبدیل یک آزمایه به یک بردار یا به عبارتی یک نقطه در یک فضای چندبعدی استفاده کرده‌اند که در ادامه، تعریف دقیق بردار فرکانس و نحوه تبدیل یک آزمایه به یک بردار در یک مثال آورده شده است.

\begin{itemize}
	\item \textbf{بردار فرکانس}
	
	فرض کنید که \(\Sigma = \{m_1, m_2, \dots, m_n\}\) لیست توابع در یک برنامه فرضی باشد و \(s\) ترتیب فراخوانی توابع توسط آزمایه \(t\) باشد. حال بردار فرکانس به صورت 
	\(f(s) = \{f_1, f_2, \dots, f_n\}\)
	 تعریف خواهد شد که \(f_i\) تعداد دفعاتی است که تابع \(m_i\) در ترتیب فراخوانی توابع (\(s\)) حضور دارد.
	
	برای مثال فرض کنید که \(\Sigma = \{a, b, c, d, e\}\) و \(s = abddc\) ترتیب فراخوانی توابع در حین اجرای آزمایه \(t\) باشد. در این وضعیت، تابع \(a\) یک بار، \(b\) یک بار، \(c\) صفر بار، \(d\) دو بار و \(e\) یک بار فراخوانی شده است. در نتیجه:
	\[
	f(s) = \{1, 1, 0, 2, 1\}
	\]
	
	حال با توجه به اینکه هر آزمایه به یک لیست عددی با طول \(n\) (یک نقطه در فضای \(n\) بعدی) تبدیل شده است، اکنون می‌توان به سادگی فاصله بین آزمایه‌ها را با استفاده از محاسبه فاصله بین نقطه‌های متناظر آزمایه‌ها به دست آورد.
	
\end{itemize}

\subsubsection{تبدیل موجک}
اگرچه تبدیل فرکانس می‌تواند به راحتی آزمایه‌های شیء‌گرا را به بردارهایی برای اندازه‌گیری عدم تشابه تبدیل کند، اما فقط بر فرکانس فراخوانی توابع تمرکز می‌کند و به ترتیب فراخوانی توابع اهمیتی نمی‌دهد. از آنجایی که ترتیب واقعی فراخوانی توابع معمولاً بر نتایج اجرا تأثیر می‌گذارد، عدم تشابه محاسبه‌شده رضایت‌بخش نیست.

برای مثال، فرض کنید \(\Sigma = \{a, b, c, d, e\}\) و \(s_1 = acbe\) ترتیب فراخوانی توابع در آزمایه \(t_1\) و \(s_2 = bcae\) ترتیب فراخوانی توابع در آزمایه \(t_2\) باشد. بعد از انجام تبدیل فرکانس، دو بردار فرکانس\\ \(f(s_1) = f(s_2) = \{1, 1, 1, 0, 1\}\) به دست خواهد آمد. فاصله بین آزمایه \(t_1\) و \(t_2\) با توجه به مقایسه بردارهای فرکانس این دو آزمایه صفر است، در حالی که ترتیب فراخوانی توابع در دو آزمایه کاملاً یکسان نیست.

از این رو، روش تبدیل موجک در این مقاله ارائه شد که علاوه بر تعداد فراخوانی هر تابع، به ترتیب فراخوانی توابع نیز تا حدی اهمیت می‌دهد. تبدیل موجک\LTRfootnote{Wavelet Transform} ابزاری ریاضی است که برای تجزیه و تحلیل سیگنال‌ها و داده‌ها در حوزه زمان و فرکانس استفاده می‌شود\cite{stankovic2005haar}\cite{egiazarian2002tree}\cite{kulkarni2011wavelet}. در این مقاله\cite{chen2021novel}، از تبدیل موجک برای اندازه‌گیری عدم تشابه بین تست‌ کیس‌های شیءگرا استفاده شده است. این معیار با تجزیه و تحلیل سیگنال‌های مربوط به ویژگی‌های آزمایه‌ها، میزان تفاوت بین آن‌ها را محاسبه می‌کند. در روش
 \lr{ART\_WTClustering} 
 از موجک هار~\LTRfootnote{Haar Wavelet}\cite{stankovic2005haar} برای نگاشت اطلاعات فرکانس و اطلاعات ترتیب فراخوانی توابع استفاده شده است. در ادامه، معیار تبدیل موجک با مثال توضیح داده شده است.

\begin{itemize}
	\item \textbf{تعریف تبدیل موجک آزمایه}
	
فرض کنید \(s = m_1 m_2 \dots m_j\) ترتیب فراخوانی توابع باشد. \(s_1\) یک زیررشته از \(s\) است که حاوی نیمه اول عناصر \(s\) است و \(s_2\) یک زیررشته دیگر از \(s\) است که حاوی نیمه دوم عناصر \(s\) است. تبدیل موجک \(s\) به صورت \(W(s) = [A, B]\) تعریف می‌شود که \(A = f(s)\) و \(B = B_1 - B_2\) که \(B_1 = f(s_1)\) و \(B_2 = f(s_2)\) است.

برای مثال فرض کنید که \(\Sigma = \{a, b, c, d, e\}\) و \(s = abdde\) ترتیب فراخوانی توابع در حین اجرای آزمایه \(t\) باشد. حال مقادیر \(A\) , \(B\) و \(W(s)\) به صورت زیر محاسبه خواهند شد:
\begin{align*}
	A = f(s) &= \{1, 1, 0, 2, 1\} \\
	s_1 = ab \quad & \Rightarrow \quad B_1 = \{1, 1, 0, 0, 0\} \\
	s_2 = dde \quad &\Rightarrow \quad B_2 = \{0, 0, 0, 2, 1\} \\
	B = B_1 - B_2 \quad &\Rightarrow \quad B = \{1, 1, 0, -2, -1\} \\
	W(s) = [A, B] \quad &\Rightarrow \quad W(s) = \left[\{1, 1, 0, 2, 1\}, \{1, 1, 0, -2, -1\}\right]
\end{align*}

\item \textbf{محاسبه فاصله بین آزمایه‌‌ها}

فرض کنید \(\Sigma = \{m_1, m_2, \dots, m_n\}\) لیست توابع درون یک برنامه فرضی باشد. اگر \(s_1\) ترتیب فراخوانی توابع توسط آزمایه \(t_1\) و \(s_2\) ترتیب فراخوانی توابع توسط آزمایه \(t_2\) باشد، آنگاه\\ \(W(s_1) = [A_1, B_1]\) و \(W(s_2) = [A_2, B_2]\) خواهد بود که \(A_1 = \{A_{11}, A_{12}, \dots, A_{1n}\}\) و \(B_1 = \{B_{11}, B_{12}, \dots, B_{1n}\}\) و \(A_2 = \{A_{21}, A_{22}, \dots, A_{2n}\}\) و \(B_2 = \{B_{21}, B_{22}, \dots, B_{2n}\}\). فاصله \(WT\_D\) بین این دو آزمایه به صورت زیر محاسبه خواهد شد:
\[
WT\_D(t_1, t_2) = \sqrt{\sum_{i=1}^{n} (A_{1i} - A_{2i})^2} + \sqrt{\sum_{i=1}^{n} (B_{1i} - B_{2i})^2}
\]


\end{itemize}

\subsubsection{تبدیل فرکانس سه‌بخشی}
اگرچه دنباله فراخوانی توابع را به دو قسمت تقسیم می‌کند و آنها را حفظ می‌کند، اما تنها تفریق نیمه اول و دوم این دنباله نمی‌تواند تفاوت بین توالی فراخوانی توابع را نمایش دهد. برای پرداختن به این موضوع، در این مقاله پیشنهاد شده است که از تبدیل فرکانس سه‌بخشی \LTRfootnote{Trisection Frequency Conversion (TFC)} استفاده شود. این معیار نه تنها به تعداد فراخوانی هر تابع در حین اجرای آزمایه‌ها توجه دارد بلکه ترتیب فراخوانی توابع در حین اجرای آزمایه‌های مختلف نیز اهمیت دارد.

\begin{itemize}

\item \textbf{تعریف معیار تبدیل فرکانس سه‌بخشی}

فرض کنید که \(s = m_1 m_2 \dots m_j\) ترتیب فراخوانی توابع در حین اجرای آزمایه \(t\) باشد و \(s_1\) نیمه اول \(s\) و \(s_2\) نیمه دوم \(s\) باشد. معیار تبدیل فرکانس سه‌بخشی برای \(s\) به صورت \(TF(s) = [A, B, C]\) نمایش داده می‌شود که \(A = f(s)\)، \(B = f(s_1)\) و \(C = f(s_2)\) است.

\item \textbf{محاسبه فاصله بین آزمایه‌‌ها}

فرض کنید \(\Sigma = \{m_1, m_2, \dots, m_n\}\) لیست توابع در یک برنامه فرضی باشد. یک آزمایه \(t_1\) با دنباله فراخوانی توابع \(s_1\) و یک آزمایه \(t_2\) با دنباله فراخوانی توابع \(s_2\) را در نظر بگیرید. فرض کنید\\ \(TF(s_1) = [A_1, B_1, C_1]\) و \(TF(s_2) = [A_2, B_2, C_2]\) که در آن \(A_1 = \{A_{11}, A_{12}, \dots, A_{1n}\}\)، \(B_1 = \{B_{11}, B_{12}, \dots, B_{1n}\}\)، \(C_1 = \{C_{11}, C_{12}, \dots, C_{1n}\}\)، \(A_2 = \{A_{21}, A_{22}, \dots, A_{2n}\}\)، \(B_2 = \{B_{21}, B_{22}, \dots, B_{2n}\}\)، و \(C_2 = \{C_{21}, C_{22}, \dots, C_{2n}\}\). تفاوت ترتیب بین \(s_1\) و \(s_2\) به صورت \(\sum_{i=1}^{j} \left(1 - \delta_{s_{1i} s_{2i}}\right)\) تعریف می‌شود، که \(\delta_{s_{1i} s_{2i}}\) نماد دلتای کرونکر استاندارد\LTRfootnote{Standard Kronecker Delta Notation} است، به طوری که اگر \(s_{1i} = s_{2i}\) باشد آنگاه \(\delta_{s_{1i} s_{2i}} = 1\) و در غیر اینصورت \(\delta_{s_{1i} s_{2i}} = 0\). فاصله \(TFC\)  یا \(TFC\_D\) بین این دو آزمایه به صورت زیر تعریف می‌شود:

\[
TFC\_D(t_1, t_2) = \sqrt{\sum_{i=1}^{n} (A_{1i} - A_{2i})^2} + \sqrt{\sum_{i=1}^{n} (B_{1i} - B_{2i})^2}
\]
\[
+ \sqrt{\sum_{i=1}^{n} (C_{1i} - C_{2i})^2} + \sum_{i=1}^{n} \left(1 - \delta_{s_{1i} s_{2i}}\right)
\quad
\]

\end{itemize}

\subsubsection{مقایسه بین \(TFC\_D\) و \(WT\_D\)}
در اینجا به بررسی تفاوت‌های \(WT\_D\) و \(TFC\_D\) در یک مثال پرداخته شده است. دو آزمایه \(t_1\) و \(t_2\) را در نظر بگیرید که ترتیب فراخوانی توابع توسط این دو آزمایه به صورت \(s_1 = abce\) و \(s_2 = abec\) است که \(s_{11} = ab\)، \(s_{12} = ce\)، \(s_{21} = ab\) و \(s_{22} = ec\) است. در نتیجه:

\begin{align*}
	W(s_1) &= \left[\langle 1, 1, 1, 0, 1 \rangle, \langle 1, 1, -1, 0, -1 \rangle \right] \\
	W(s_2) &= \left[\langle 1, 1, 1, 0, 1 \rangle, \langle 1, 1, -1, 0, -1 \rangle \right]
\end{align*}

است و در نتیجه \({WT\_D}(s_1, s_2)\) برابر است با:

\[
WT\_D(s_1, s_2) = \sqrt{0^2 + 0^2 + 0^2 + 0^2 + 0^2} + \sqrt{0^2 + 0^2 + 0^2 + 0^2 + 0^2} = 0
\]
از طرفی با توجه به تعریف \(TF(s_i)\) مقادیر \(TF(s_1)\) و \(TF(s_2)\) و \(TFC\_D(s_1, s_2)\) به صورت زیر محاسبه می‌شوند:
\[
TF(s_1) = \left[\langle 1, 1, 1, 0, 1 \rangle, \langle 1, 1, 0, 0, 0 \rangle, \langle 0, 0, 1, 0, 1 \rangle\right]
\]
\[
TF(s_2) = \left[\langle 1, 1, 1, 0, 1 \rangle, \langle 1, 1, 0, 0, 0 \rangle, \langle 0, 0, 1, 0, 1 \rangle\right]
\]
\(TFC\_D(s_1, s_2)\) به صورت زیر محاسبه می‌شود:
\begin{align*}
	TFC\_D(s_1, s_2) &= \sqrt{0^2 + 0^2 + 0^2 + 0^2 + 0^2} + \sqrt{0^2 + 0^2 + 0^2 + 0^2 + 0^2} \\
	&\quad + \sqrt{0^2 + 0^2 + 0^2 + 0^2 + 0^2} + \sum_{i=1}^{j} \left(1 - \delta_{s_{1i}s_{2i}}\right)
\end{align*}
که
\[
\sum_{i=1}^{j} \left(1 - \delta_{s_{1i}s_{2i}}\right) = (1-1) + (1-1)  + (1-0)  + (1-0) = 2
\]
بنابراین:
\[
TFC\_D(s_1, s_2) = 0 + 0 + 0 + 2 = 2 
\]
همانطور که مشاهده کردید،‌ فاصله \(TFC\) در این مثال نسبت به فاصله \(ٌُWT\)  به ترتیب فراخوانی توابع توسط آزمایه‌ها اهمیت بیشتری می دهد.

\subsubsection{فلوچارت روش‌های مبتنی بر خوشه‌بندی}

در شکل \ref{clusteringflowchart}، روال کار تولید آزمایه تصادفی تطبیقی توسط روش‌های مبتنی بر خوشه‌بندی تعریف شده در پژوهش \cite{chen2021novel} در قالب یک فلوچارت، قابل مشاهده است.

ابتدا 10 آزمایه به صورت تصادفی تولید می‌شود. سپس، آزمایه‌های انتخاب‌شده در مراحل قبلی با استفاده از الگوریتم خوشه‌بندی \lr{K}-مرکز در \lr{K} خوشه قرار می‌گیرند و \lr{K} آزمایه به عنوان نماینده از این \lr{K} خوشه انتخاب می‌شود. در انتها، یکی از 10 آزمایه که بیشترین فاصله را با \lr{K} آزمایه نماینده دارد، انتخاب می‌شود. شرط خاتمه نیز می‌تواند تولید تعداد مشخصی آزمایه یا شناسایی شکست در سیستم تحت آزمون باشد.

\newpage
\begin{figure}[H]
	\begin{tikzpicture}[node distance=2.5cm]
		
		\node (start) [startstop, text width=8cm, align=center] {\rl{به صورت تصادفی اولین مورد آزمایشی شئ‌گرا را ایجاد کرده و اجرا کنید}};
		\node (decision) [decision, below of=start, yshift=-1cm, text width=2cm, align=center] {\rl{شرط خاتمه}};
		\node (output) [startstop, right of=decision, xshift=4cm, align=center] {\rl{خروجی آزمایه‌های تولید شده}};
		\node (process1) [process, below of=decision, yshift=-1cm, text width=8cm, align=center] {\rl{اضافه کردن این آزمایه به مجموعه آزمایه‌های انتخاب شده در مراحل قبلی الگوریتم}};
		\node (process2) [process, below of=process1, yshift=-0.2cm, text width=8cm, align=center] {\rl{تولید ۱۰ آزمایه شئ‌گرا جدید به عنوان مجموعه کاندید}};
		
		\node (process3) [process, below of=process2, yshift=-0.2cm, text width=8cm, align=center] {\rl{خوشه‌بندی مجموعه آزمایه‌های از قبل انتخاب شده به \rl{K} خوشه}};
		\node (process4) [process, below of=process3, yshift=-0.2cm, text width=8cm, align=center] {\rl{تعیین نماینده هر خوشه برای ارزیابی آزمایه‌های کاندید}};
		\node (process5) [process, below of=process4, yshift=-0.2cm, text width=8cm, align=center] {\rl{انتخاب آزمایه‌ای که بیشترین فاصله را با نمایندگان مجموعه آزمایه‌های انتخاب‌شده در مراحل قبلی الگوریتم دارد}};
		
		\draw [arrow] (start) -- (decision);
		\draw [arrow] (decision) -- node[anchor=east] {No} (process1);
		\draw [arrow] (decision) -- node[anchor=north] {Yes} (output);
		\draw [arrow] (process1) -- (process2);
		\draw [arrow] (process2) -- (process3);
		\draw [arrow] (process3) -- (process4);
		\draw [arrow] (process4) -- (process5);
		\draw [arrow] (process5.west) -| ++(-1,0) |- (decision.west);
	\end{tikzpicture}
	\caption{فلوچارت روش آزمون تصادفی تطبیقی مبتنی بر محاسبه فاصله و استراتژی خوشه‌بندی}
	\label{clusteringflowchart}
\end{figure}

\subsection{نقطه اشتراک اکثر روش‌های پیاده‌سازی الگوریتم آزمون تصادفی تطبیقی}

تقریباً چالش همه مقالاتی که تاکنون در این زمینه ارائه شده‌اند، این بوده است که روشی برای ارزیابی آزمایه‌های مجموعه کاندید ارائه دهند و متفاوت‌ترین آزمایه نسبت به مجموعه آزمایه‌های انتخاب شده قبلی را انتخاب کرده و به مجموعه آزمایه‌های خود اضافه کنند. نمونه‌هایی از این روش‌ها در بالا با ذکر مثال تشریح شدند. همان‌طور که مشاهده کردید، در این پیاده‌سازی‌ها تلاش بر این بوده است که در هر مرحله از الگوریتم آزمون تصادفی تطبیقی، یک استراتژی برای تبدیل آزمایه‌ها به مجموعه‌ای از نقطه‌ها در مجموعه‌ای از فضاهای چندبعدی فرضی ارائه شود. سپس با استفاده از فاصله بین این نقطه‌ها، میزان تفاوت بین آزمایه‌های مجموعه کاندید و آزمایه‌های انتخاب شده در مراحل قبلی الگوریتم محاسبه شده و متفاوت‌ترین آزمایه انتخاب شود.

علاوه بر این، برخی از روش‌ها از مولفه‌هایی درون خود آزمایه برای محاسبه فاصله استفاده می‌کنند و برخی دیگر با استفاده از نتایج اجرای هر آزمایه درون مجموعه کاندید، مولفه‌هایی تعریف می‌کنند. سپس با استفاده از این مولفه‌ها به ارزیابی آزمایه‌ها پرداخته و در نهایت آزمایه‌ای که به اصطلاح بیشترین تفاوت را با مجموعه کاندید دارد، انتخاب می‌شود.

\section{روش تقسیم‌بندی فضای ورودی}

همان‌طور که تاکنون شرح داده شد، هدف روش آزمون تصادفی تطبیقی، متراکم کردن آزمایه‌ها بر روی فضای ورودی است تا همه حالت‌های ممکن را دربرگیرد و به اصطلاح مجموعه آزمایه‌های کاملی را ارائه دهد.

روش تقسیم‌بندی فضای ورودی\LTRfootnote{Input Space Partitioning (ISP)} نیز یک روش آزمون دستی\LTRfootnote{Manual Testing} نرم‌افزار است که با استفاده از استراتژی‌های مختلف سعی دارد آزمایه‌های کامل و متفاوت از یکدیگر را درون مجموعه آزمایه‌های خود اضافه کند. در این روش، فضای ورودی به قسمت‌های مختلفی تقسیم‌بندی می‌شود و در فرآیند تولید آزمایه با استفاده از این روش، هدف تولید آزمایه‌هایی است که همه این قسمت‌های تعریف‌شده توسط آزمونگر را پوشش دهند. به این ترتیب، مجموعه آزمایه کاملی برای آزمون سیستم تحت آزمون تولید می‌شود.

\subsection{فرآیند تولید آزمایه توسط روش تقسیم‌بندی فضای ورودی}

در این روش، آزمونگر یک مجموعه خصیصه\LTRfootnote{Characteristic} با توجه به ورودی‌ها و خروجی‌های مختلف برنامه تحت آزمون و یا رفتاری که سیستم تحت آزمون از خود نشان می‌دهد، تعریف می‌کند که هر کدام از این خصیصه‌ها به قسمت‌های مختلفی بخش‌بندی\LTRfootnote{Partition} می‌شود. برای درک بهتر، در ادامه با تعریف یک سیستم تحت آزمون و خصیصه‌های پیشنهادی برای آن، به توضیح دقیق این روش پرداخته شده است.

برای مثال فرض کنید که سیستم تحت آزمون ما یک برنامه است که حاصل یک عبارت ریاضی حاوی ۴ عملیات اصلی ضرب، جمع، تقسیم و تفریق که به صورت رشته به آن داده شده است را محاسبه کرده و به عنوان خروجی پس می‌دهد. به عنوان مثال، خروجی این برنامه به ازای رشته ورودی \lr{”2+3”} باید \lr{5} باشد.

در ادامه چند خصیصه‌ای که آزمونگر می‌تواند برای این سیستم تحت تست در نظر بگیرد، مثال زده شده است.

\textbf{لیست خصیصه‌ها و بخش‌بندی تعریف شده برای هر کدام از این خصیصه‌ها:}

\begin{enumerate}
	\item \textbf{تعداد عملگرهای درون رشته ورودی}
	\begin{enumerate}
		\item \textbf{صفر:} به عنوان مثال رشته \lr{”5”}
		\item \textbf{یک:} به عنوان مثال رشته \lr{”1+2”}
		\item \textbf{بیشتر از یک:} به عنوان مثال رشته \lr{”2+3+4”}
	\end{enumerate}
	
	\item \textbf{تعداد عملوندهای درون رشته ورودی}
	\begin{enumerate}
		\item \textbf{صفر:} به عنوان مثال رشته \lr{””}
		\item \textbf{یک:} به عنوان مثال رشته \lr{”-1”}
		\item \textbf{دو:} به عنوان مثال رشته \lr{”1*5”}
		\item \textbf{بیشتر از دو:} به عنوان مثال رشته \lr{”1*5-3”}
	\end{enumerate}
	
	\item \textbf{کاراکترهای ورودی}
	\begin{enumerate}
		\item \textbf{حاوی کاراکترهای غیرمجاز:} به عنوان مثال رشته \lr{”a+b”}
		\item \textbf{بدون کاراکتر غیرمجاز:} به عنوان مثال رشته \lr{”1+1”}
	\end{enumerate}
	
	\item \textbf{و ...}
\end{enumerate}

حال آزمونگر با استفاده از ترکیب بخش‌بندی‌های مختلف هر خصیصه با دیگر خصیصه‌ها، آزمایه‌های مدنظر خود را تولید می‌کند. برای مثال از ترکیب بخش‌بندی‌های 1.ج، ۲.ج و ۳.ب آزمایه زیر به دست خواهد آمد:

در این آزمایه باید تعداد عملگرها بیشتر از یک و تعداد عملوند‌ها برابر دو و کاراکترهای ورودی حاوی کاراکتر غیرمجاز نباشد. به عنوان مثال می‌توان رشته \lr{”-2+3”} را برای این ترکیب مثال زد و به عنوان آزمایه در نظر گرفت.

\textbf{دو نکته مهم در تعریف بخش‌بندی هر خصیصه}

\begin{itemize}
	\item \textbf{کامل بودن}
	
	بخش‌های تعریف شده برای هر خصیصه باید در کنار هم همه حالت‌هایی که آن خصیصه می‌تواند داشته باشد را پوشش دهند.
	
	\item \textbf{عدم اشتراک}
	
	بخش‌های تعریف شده برای هر خصیصه نباید با یکدیگر اشتراک داشته باشند. به عبارت دیگر، هر ورودی ممکن برنامه تحت آزمون باید دقیقاً یکی از بخش‌های تعریف شده برای هر خصیصه را پوشش دهد.
\end{itemize}

در نهایت، آزمونگر با استفاده از ترکیب بخش‌بندی خصیصه‌هایی که برای سیستم تحت آزمون تعریف کرده است، آزمایه‌هایی را تولید می‌کند که این آزمایه‌ها همه بخش‌های مختلف فضای ورودی سیستم تحت آزمون را پوشش می‌دهند.
